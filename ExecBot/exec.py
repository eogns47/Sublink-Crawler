import time
import os
import sys
from tqdm import tqdm
import logging
import io
import subprocess


class TqdmToLogger(io.StringIO):
    """
        Output stream for TQDM which will output to logger module instead of
        the StdOut.
    """
    logger = None
    level = None
    buf = ''

    def __init__(self, logger, level=None):
        super(TqdmToLogger, self).__init__()
        self.logger = logger
        self.level = level or logging.INFO

    def write(self, buf):
        self.buf = buf.strip('\r\n\t ')

    def flush(self):
        self.logger.log(self.level, self.buf)


# inputs ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°ú ÏÑ§Ï†ï
# -------------------------------------------- Setting relative path --------------------------------------------#
script_path = os.path.abspath(__file__)
path_parts = script_path.split('/')
root_index = path_parts.index('ExecBot')
relative_path_parts = path_parts[:root_index]
relative_path = '/'.join(relative_path_parts)

# # Î°úÍ∑∏ ÌååÏùº ÏÑ§Ï†ï
logging.basicConfig(filename=relative_path+'/logs/exec.log',
                    format='(%(asctime)s) %(levelname)s:%(message)s',
                    level=logging.DEBUG)
logger = logging.getLogger()

# -------------------------------------------- Reading targets.txt --------------------------------------------#
input_directory = os.path.join(relative_path, 'inputs')
target_file_path = os.path.join(input_directory, 'targets.txt')

url_list = []
# targets.txt ÌååÏùº ÏùΩÍ∏∞
with open(target_file_path, 'r') as file:
    file_content = file.read()
    url_list = file_content.split('\n')


# -------------------------------------------- Executing link-crawler --------------------------------------------#
def check_ResultFile_exist(resultFile):
    # resultFileÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏúºÎ©¥ ÏÉùÏÑ±
    resultPath = relative_path+'/results/'+resultFile
    if not os.path.exists(resultPath):
        os.system(f'touch {resultPath}')
        print(f'{resultPath} is created')
    else:
        print(f'{resultFile} is already exist')
        exit(0)


def check_ErrorListFile_exist(resultFile):
    # errorListFileÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏúºÎ©¥ ÏÉùÏÑ±
    errorListPath = relative_path+'/results/errorList.txt'
    if not os.path.exists(errorListPath):
        os.system(f'touch {errorListPath}')
        with open(errorListPath, 'a') as errorFile:
            errorFile.write(f'üö®ErrorList of {resultFile} üö®\n')
    else:
        # ÏóêÎü¨Î¶¨Ïä§Ìä∏ ÌååÏùºÏóê hello ÏûëÏÑ±
        with open(errorListPath, 'a') as errorFile:
            errorFile.write(f'üö®ErrorList of {resultFile} üö®\n')


def exec_link_crawler(resultFile, depth: int):
    # link-crawler Ìè¥Îçî Í≤ΩÎ°ú ÏÑ§Ï†ï
    parent_directory = os.path.join(relative_path, "src")
    # Ìïú Îã®Í≥Ñ ÏúÑ Ìè¥ÎçîÎ°ú Ïã§Ìñâ ÏúÑÏπò Î≥ÄÍ≤Ω
    os.chdir(parent_directory)
    tqdm_out = TqdmToLogger(logger, level=logging.INFO)
    logger.info('üöÄ Crawling For %s', resultFile)
    logger.info('‚è∞ Crawling Start time: %s', time.strftime(
        '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))
    for url in tqdm(url_list, desc='Crawling Processing', unit='item', file=tqdm_out, mininterval=30):
        # 0.5Ï¥à ÎåÄÍ∏∞
        os.system(f'rm ../inputs/tmp.txt')
        os.system(f'echo {url} >> ../inputs/tmp.txt')
        # os.system(f'node index.js -t tmp.txt -r test.txt -d 1')

        command = "node index.js -t tmp.txt -r " + resultFile + " -d " + depth
        result = subprocess.Popen(command, shell=True)
        returncode = result.wait()

    logger.info('‚è∞ Crawling End time: %s', time.strftime(
        '%Y-%m-%d %H:%M:%S', time.localtime(time.time())))


# -------------------------------------------- Main --------------------------------------------#
if __name__ == "__main__":
    argv = sys.argv
    if (len(argv) < 3):
        print("Usage: python3 exec.py [resultFile] [depth]")
    elif (len(argv) == 3):
        check_ResultFile_exist(argv[1])
        check_ErrorListFile_exist(argv[1])
        exec_link_crawler(argv[1], argv[2])
    else:
        print("Usage: python3 exec.py [resultFile] [depth]")
